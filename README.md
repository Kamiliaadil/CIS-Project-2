# CIS-Project-2

Brain Tumor Detection

   1. Problem statement:
    
A primary brain or spinal cord tumor originates within the brain or spinal cord itself. Brain tumors constitute a significant majority, accounting for 85% to 90% of all primary central nervous system (CNS) tumors. Globally, around 308,102 individuals received a diagnosis of a primary brain or spinal cord tumor in the year 2020. Brain tumors present a complex challenge due to their diverse characteristics, including variations in size and location. Understanding the nature of these tumors is intricate, often necessitating the expertise of a professional neurosurgeon for thorough MRI analysis. In regions with limited medical resources, such as developing countries, the scarcity of skilled medical practitioners and insufficient awareness about tumors exacerbates the difficulties in generating MRI reports. To address this issue, the implementation of an automated cloud-based system emerges as a potential solution. Detecting brain tumors encounters a significant hurdle stemming from the diversity observed in tumor attributes, such as their shapes, sizes, and locations. 
   
   2. Literature review:
      
In the realm of brain tumor detection, researchers have delved into diverse classification algorithms and techniques aimed at refining accuracy and bolstering the reliability of diagnoses. These approaches encompass a spectrum of strategies, including feature extraction methodologies that extract vital attributes from MRI images, subsequently aiding in the differentiation of distinct tumor types. Moreover, image preprocessing techniques have been explored to enhance the quality of input data by mitigating noise and adjusting contrast. Machine learning algorithms, such as Decision Trees, Support Vector Machines, and Random Forests, have been harnessed to facilitate precise categorization. Deep learning paradigms like Convolutional Neural Networks have gained prominence for their capacity to autonomously discern salient features from images. Ensemble methods, data augmentation, dimensionality reduction, and hyperparameter tuning have been harnessed to further optimize classification outcomes. The integration of transfer learning and post-processing techniques has also demonstrated promise in augmenting the precision of model predictions. As a whole, these varied techniques collectively contribute to the advancement of brain tumor detection, equipping medical professionals with potent tools for early and accurate diagnoses.
  
  3. Data description:
     
The data used in this project originates from a dataset accessible on Kaggle. This dataset contains a total of 3264 MRI images, categorized into four distinct groups: Glioma, Meningioma, Pituitary, and No Tumor (Healthy). Gliomas represent a prevalent form of brain tumor, originating from specific brain cells referred to as glial cells. Meningioma and Pituitary are non-glioma tumors, arising from brain cells other than glial cells. Meningiomas stand out as the most common primary brain tumors, while pituitary gland tumors originate from either the pineal or pituitary glands. The images in this dataset are in jpg format, and the size of input images is 64Ã—64.

   4. Methodology:
   
To compare different types of brain tumor classifications. I started organizing the image data into distinct groups based on specific keywords found in the image filenames. For instance, images featuring the identifier 'gg' were designated as 1, representing glioma tumor images. Similarly, those with the keyword 'meningioma' were denoted as 2, signifying meningioma tumor images. The 'pituitary' keyword corresponded to category 3, indicative of pituitary tumor images. Likewise, filenames containing 'no' were allocated category 4, implying images without tumors.
I then created a balanced dataset for analysis, I randomly selected a specific sample size, which I denoted as 300. The aim was to ensure that each category had the same number of samples for fair comparison. Subsequently, I used the grouped dataset to create three sub-datasets for different comparisons: no tumor vs. glioma tumor, no tumor vs. meningioma tumor, and no tumor vs. pituitary tumor. Then, I assigned numbers to each category for clarity: 1 for glioma tumor, 2 for meningioma tumor, 3 for pituitary tumor, and 4 for no tumor. The process allowed me to effectively compare different tumor types against the 'no tumor' cases.
Subsequently, I delved into the extraction of vital features from the images within each distinct category. This process incorporated various methodologies: I initiated by examining the Red-Green-Blue (RGB) channels to capture color information, then implemented the Local Binary Pattern (LBP) technique to unveil intricate texture patterns. Additionally, I harnessed the Prewitt kernel to quantify horizontal and vertical edge details, which are instrumental in capturing structural attributes.
Following feature extraction, I collated the obtained features into a comprehensive matrix, laying the groundwork for subsequent classification tasks. To ensure uniformity and reliability, I segregated the data into separate training and testing sets through established train-test splitting methodologies. Standardization was applied using the StandardScaler to warrant consistent scaling across the distinct feature extraction techniques
For classification, I employed several machine learning algorithms, including Decision Tree, K-Nearest Neighbors (KNN), Gaussian Naive Bayes (GNB), Random Forest, Support Vector Machine (SVM) with various kernel functions, and Logistic Regression. To assess the accuracy of each model, I used cross-validation techniques and computed the classification accuracy along with standard deviations. Additionally, I utilized classification reports and Jaccard Accuracy Scores to provide a comprehensive understanding of the models' performance.
Furthermore, I explored unsupervised machine learning using K-means clustering and delved into deep learning with MLP and CNN architectures. These approaches allowed me to understand patterns and extract features from the data without relying on pre-labeled information, giving me insights into the dataset's structure.
My main goal in evaluating the models was to find the most effective one for correctly classifying images with brain tumors. By identifying the model that performed the best in this task, I intend to choose a practical tool that can have real-world benefits.
Once I find the best model, my next step is to put it into a user-friendly Python setup using Flask. This way, people with different levels of technical knowledge can easily use the model without any difficulties. Ultimately, what I'm aiming for is to help in the accurate classification of brain tumors, which can have a positive impact on public health.

   5. Results:
  
For the classification of "No Tumor" versus "Glioma Tumor," Logistic Regression, Linear SVM, and Sigmoid SVM demonstrated consistent and strong results, achieving 96% across all metrics. Polynomial SVM and RBF SVM underperformed with accuracy of 59% and 57%, respectively. Decision Tree and Gaussian Naive Bayes performed well with accuracy at 95% and 91%, respectively. Notably, the Random Forest Classifier stood out with a remarkable accuracy of 98% and balanced precision, recall, and F1 scores. Lastly, it's worth noting that the Jaccard accuracy and cross-validation accuracy are closely aligned with the accuracy results obtained from the classification report for all models.
In the "No Tumor" and "Meningioma Tumor" classifications, Logistic Regression, Linear SVM, and DT consistently demonstrated performance with 86%, 87%, and 85% accuracy respectively. Sigmoid SVM achieved a notable 88% accuracy, while KNN showcased an accuracy of 74%, alongside closely aligned precision and recall values. Gaussian Naive Bayes achieved an accuracy of 78%, and the Random Forest Classifier excelled with a commendable 91% accuracy and closely matched metrics. Polynomial SVM and RBF SVM displayed comparatively lower performance with accuracies of 58% and 57% respectively. While the Jaccard accuracy mirrored the accuracy results from the classification report, the classification accuracy saw a slight increase compared to the cross-validation accuracy.
Lastly, the classification of "No Tumor" versus "Pituitary Tumor" demonstrated strong results across models. Logistic Regression, Linear SVM, and Sigmoid SVM consistently achieved 96% accuracy and balanced metrics. Sigmoid SVM achieved an accuracy of 97%. DT maintained a solid accuracy of 95%, while KNN exhibited a notable accuracy of 81% with harmonized precision, recall, and F1 scores. GNB and RFC showed strong performances with accuracy of 95% and 99%, respectively. Polynomial SVM and RBF SVM had comparatively lower accuracy of 61% and 57%. The Jaccard accuracy and cross-validation accuracy exhibited strong concurrence with the accuracy results derived from the classification report across all models. Notably, RFC's exceptional 100% cross-validation accuracy serves to reinforce its credibility and reliability.

In my exploration of the K-means clustering algorithm, I identified that the elbow point occurred at K = 3. However, upon visualizing the resulting clusters, I observed that they were distributed in a disorganized manner, lacking clear separation. Notably, cluster number three exhibited the highest prevalence. When assessing the quality of these clusters using the purity score, I obtained an overall score of 62.17%. This score remained consistent across different distance metrics, including Euclidean, squared Euclidean, and chi-square distances. Interestingly, the clusters showed better separation with Manhattan and Canberra distances, achieving purity scores of 72.17% and 84.67% respectively. The cluster separation was notably weak when using Chebyshev distance, yielding a purity score of 50.83%. In short, my research indicates that the K-means algorithm didn't work well for this dataset. The clusters didn't have clear boundaries and the results varied when using different ways to measure the distance between points.
The MLP classification report reveals that the model achieved an overall accuracy of 72% in its classification of brain tumor images across various categories. Precision values exhibited diversity among the categories, ranging from 63% for Category 0 to 94% for Category 1, 66% for Category 2, and 84% for Category 3. Similarly, recall values displayed distinct patterns, with the highest recall of 94% observed for category 2, followed by 92% for category 3, 83% for category 0, and the lowest recall of 21% for category 1. F1 scores also reflected this variation, spanning from 34% for category 1 to 87% for category 3, with intermediate scores of 71% for category 0 and 77% for category 2. The weighted average precision, recall, and F1-score were 77%, 72%, and 68% respectively, signifying a moderate overall performance of the MLP model in categorizing brain tumor images. Notably, the model exhibited a higher rate of misclassification for category 1.
The CNN model achieved an accuracy of 25% on the test data, indicating moderate alignment between predictions and actual labels. However, class-specific analysis reveals varying performance. For the first class (label 0), the model achieved perfect precision but had low recall, implying difficulty in identifying instances of this class. The second class (label 1) showed balanced precision and recall, resulting in a moderate F1 score. In the third and fourth classes (labels 2 and 3), the model exhibited high precision but low recall, indicating challenges in identifying instances.
Since the Random Forest classifier demonstrated the highest level of performance when compared to the other models, I made the decision to deploy it on PythonAnywhere. By doing so, I've provided an accessible platform for others to leverage the model's impressive predictive capabilities. My hope is that this deployment proves beneficial and valuable to those seeking accurate predictions for their own datasets. 
   
   6. Next step:
   7. 
As I reflect on this project, I recognize several limitations that warrant attention. Firstly, my dataset is comprised of only 300 jpg MRI images per category. 
Expanding the dataset's scope to include various data formats and increasing the sample size could enhance the model's ability to handle diverse cases effectively.

